{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d6247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading checkpoint from checkpoint.pth...\n",
      " Resumed from epoch 23, best val acc 0.9917\n",
      "\n",
      "=== Epoch 24/25 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9850 | Val Acc: 0.9915\n",
      " Checkpoint saved!\n",
      "\n",
      "=== Epoch 25/25 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9846 | Val Acc: 0.9917\n",
      " Checkpoint saved!\n",
      "\n",
      " Training complete!\n",
      " Best Validation Accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ========================================\n",
    "# CONFIG\n",
    "# ========================================\n",
    "DATA_DIR = r\"D:/viot/Data__Split\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 3\n",
    "NUM_EPOCHS = 25\n",
    "DEVICE = torch.device(\"cpu\")  # CPU only\n",
    "LR = 1e-3\n",
    "PATIENCE = 4\n",
    "CHECKPOINT_PATH = \"checkpoint.pth\"\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "# ========================================\n",
    "# DATA\n",
    "# ========================================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=train_transform)\n",
    "val_dataset   = datasets.ImageFolder(f\"{DATA_DIR}/val\", transform=val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ========================================\n",
    "# MODEL\n",
    "# ========================================\n",
    "model = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
    "for param in model.features[:-1].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(in_features, NUM_CLASSES)\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# ========================================\n",
    "# LOAD CHECKPOINT (if exists)\n",
    "# ========================================\n",
    "start_epoch = 0\n",
    "best_val_acc = 0\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\" Loading checkpoint from {CHECKPOINT_PATH}...\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_acc = checkpoint['best_val_acc']\n",
    "    print(f\" Resumed from epoch {start_epoch}, best val acc {best_val_acc:.4f}\")\n",
    "\n",
    "# ========================================\n",
    "# TRAIN LOOP\n",
    "# ========================================\n",
    "no_improve = 0\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    print(f\"\\n=== Epoch {epoch+1}/{NUM_EPOCHS} ===\")\n",
    "\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    loop = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for imgs, labels in loop:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        loop.set_postfix(loss=loss.item(), acc=f\"{correct/total:.4f}\")\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss = running_loss / total\n",
    "\n",
    "    # ---------- VALIDATION ----------\n",
    "    model.eval()\n",
    "    correct_val, total_val = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_val += (preds == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "    val_acc = correct_val / total_val\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ---------- SAVE CHECKPOINT ----------\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_val_acc': best_val_acc\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "    print(\" Checkpoint saved!\")\n",
    "\n",
    "    # ---------- SAVE BEST MODEL ----------\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_cpu_model.pth\")\n",
    "        print(f\" New best model saved with Val Acc: {val_acc:.4f}\")\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(\" Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"\\n Training complete!\")\n",
    "print(f\" Best Validation Accuracy: {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ab128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================\n",
    "# CONFIG\n",
    "# ==============================\n",
    "DATA_DIR = r\"D:/viot/Data_Split_Stage2\"  \n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20\n",
    "DEVICE = torch.device(\"cpu\")  \n",
    "LR = 1e-3\n",
    "PATIENCE = 6\n",
    "CHECKPOINT_PATH = \"disease_stage2_checkpoint.pth\"\n",
    "BEST_MODEL_PATH = \"disease_stage2_best_model.pth\"\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "# ==============================\n",
    "# DATASET AND TRANSFORMS\n",
    "# ==============================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"), transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "NUM_CLASSES = len(train_dataset.classes)\n",
    "print(f\" Number of specific disease classes: {NUM_CLASSES}\")\n",
    "print(\" Disease class names:\")\n",
    "for cls in train_dataset.classes:\n",
    "    print(\"-\", cls)\n",
    "\n",
    "# ==============================\n",
    "# MODEL\n",
    "# ==============================\n",
    "model = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")  \n",
    "\n",
    "# Freeze feature layers for faster training\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(in_features, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# ==============================\n",
    "# LOSS, OPTIMIZER, SCHEDULER\n",
    "# ==============================\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# ==============================\n",
    "# RESUME CHECKPOINT IF EXISTS\n",
    "# ==============================\n",
    "start_epoch = 0\n",
    "best_val_acc = 0.0\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\" Loading checkpoint from {CHECKPOINT_PATH}...\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    best_val_acc = checkpoint[\"best_val_acc\"]\n",
    "    print(f\" Resumed at epoch {start_epoch}, Best Val Acc: {best_val_acc:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# TRAINING LOOP\n",
    "# ==============================\n",
    "no_improve = 0\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    print(f\"\\n=== Epoch {epoch+1}/{NUM_EPOCHS} ===\")\n",
    "\n",
    "    # ---------- TRAIN ----------\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    loop = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for imgs, labels in loop:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        loop.set_postfix(loss=loss.item(), acc=f\"{correct/total:.4f}\")\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss = running_loss / total\n",
    "\n",
    "    # ---------- VALIDATION ----------\n",
    "    model.eval()\n",
    "    correct_val, total_val = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_val += (preds == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    val_acc = correct_val / total_val\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ---------- SAVE CHECKPOINT ----------\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"best_val_acc\": best_val_acc\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "    # ---------- SAVE BEST MODEL ----------\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f\" New best model saved (Val Acc: {best_val_acc:.4f})\")\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(\" Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"\\n Training complete!\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
